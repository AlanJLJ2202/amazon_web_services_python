{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9ac29880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO, BytesIO\n",
    "from datetime import datetime, timedelta\n",
    "import pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "51849c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapter Layer\n",
    "\n",
    "def read_csv_to_df(bucket, objects):\n",
    "    #Se lee el primer objeto para obtener el nombre de las columnas\n",
    "    csv_obj_init = bucket.Object(key=objects[0].key).get().get('Body').read().decode('utf-8') \n",
    "    data = StringIO(csv_obj_init)\n",
    "    df_init = pd.read_csv(data, delimiter=',')\n",
    "\n",
    "    df_all = pd.DataFrame(columns=df_init.columns)\n",
    "\n",
    "    for obj in objects:\n",
    "        csv_obj = bucket.Object(key=obj.key).get().get('Body').read().decode('utf-8')\n",
    "        data = StringIO(csv_obj)\n",
    "        df = pd.read_csv(data, delimiter=',')\n",
    "        df_all = pd.concat([df,df_all], ignore_index=True)\n",
    "    \n",
    "    print('SE HA LEIDO EL ARCHIVO CSV CORRECTAMENTE')\n",
    "    return df_all\n",
    "\n",
    "def write_df_to_s3(df_all, key, bucket_target):\n",
    "    \n",
    "    #Se inicializa el buffer de salida, en este caso se utiliza BytesIO para que el buffer sea de bytes\n",
    "    out_buffer = BytesIO()\n",
    "    df_all.to_parquet(out_buffer, index=False)\n",
    "    bucket_target.put_object(Body=out_buffer.getvalue(), Key=key)\n",
    "\n",
    "    print('SE HA CARGADO EL ARCHIVO PARQUET CORRECTAMENTE')\n",
    "    pass\n",
    "\n",
    "def return_objects(bucket, arg_date_dt):\n",
    "    \n",
    "    #Get all the objects according to the condition given and return them\n",
    "    objects = [obj for obj in bucket.objects.all() if datetime.strptime(obj.key.split(\"/\")[0], '%Y-%m-%d').date() >= arg_date_dt]\n",
    "    \n",
    "    print('SE HAN ENCONTRADO LOS OBJETOS CORRECTAMENTE')\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "05c77de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application Layer\n",
    "\n",
    "def extract(bucket, args):\n",
    "    #se obtienen los objetos que cumplen con la condicion\n",
    "    objects = return_objects(bucket, args)\n",
    "    \n",
    "    #Se lee el archivo csv y se transforma en un dataframe\n",
    "    df_all = read_csv_to_df(bucket, objects)\n",
    "    \n",
    "    print('SE HAN EXTRAIDO LOS DATOS CORRECTAMENTE')\n",
    "    return df_all\n",
    "\n",
    "def transform_report(df_all, arg_date):\n",
    "    \n",
    "    #Se transforma el dataframe para obtener el reporte diario\n",
    "    df_all.dropna(inplace=True)\n",
    "\n",
    "    df_all['opening_price'] = df_all.sort_values(by=['Time']).groupby(['ISIN', 'Date'])['StartPrice'].transform('first')\n",
    "    df_all['closing_price'] = df_all.sort_values(by=['Time']).groupby(['ISIN', 'Date'])['EndPrice'].transform('last')\n",
    "    df_all = df_all.groupby(['ISIN', 'Date'], as_index=False).agg(opening_price_eur=('opening_price', 'min'), closing_price_eur=('closing_price', 'min'), minimum_price_eur=('MinPrice', 'min'), maximum_price_eur=('MaxPrice', 'max'), daily_traded_volume=('TradedVolume', 'sum'))\n",
    "    df_all['prev_closing_price'] = df_all.sort_values(by=['Date']).groupby(['ISIN'])['closing_price_eur'].shift(1)\n",
    "    df_all['change_prev_closing_%'] = (df_all['closing_price_eur'] - df_all['prev_closing_price']) / df_all['prev_closing_price'] * 100\n",
    "    df_all.drop(columns=['prev_closing_price'], inplace=True)\n",
    "    df_all = df_all.round(decimals=2)\n",
    "    df_all.reset_index(inplace=True)\n",
    "    df_all = df_all[df_all.Date >= arg_date] \n",
    "    \n",
    "    print('SE HA TRANSFORMADO EL DATAFRAME')\n",
    "    return df_all\n",
    "\n",
    "def load(df_all, bucket_target):\n",
    "    #Se genera un identificador unico para el archivo\n",
    "    key = 'xetra_daily_report_' + datetime.today().strftime(\"%Y%m%d_%H%M%S\") + '.parquet'\n",
    "    \n",
    "    #Se escribe el dataframe en el bucket de destino dentro de AWS S3\n",
    "    write_df_to_s3(df_all, key, bucket_target)\n",
    "    pass\n",
    "\n",
    "def etl_report(bucket_target):\n",
    "\n",
    "    ultimo_objeto = None\n",
    "    objetos = list(bucket_target.objects.all())\n",
    "    cantidad_objetos = len(objetos)\n",
    "    i = 0\n",
    "    for obj in bucket_target.objects.all():\n",
    "       i += 1\n",
    "       if i == cantidad_objetos:\n",
    "           ultimo_objeto = obj\n",
    "           #Identificador del ultimo archivo encontrado dentro del bucket\n",
    "           print(ultimo_objeto.key)\n",
    "\n",
    "           #Se obtiene el ultimo objeto del bucket de destino\n",
    "           prq_obj = bucket_target.Object(ultimo_objeto.key).get().get('Body').read()\n",
    "           data = BytesIO(prq_obj)\n",
    "           df_report = pd.read_parquet(data)\n",
    "           break\n",
    "       \n",
    "    print('SE HA LEIDO EL ARCHIVO PARQUET DESTINO CORRECTAMENTE')\n",
    "    return df_report\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "015346ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion Main\n",
    "def main():\n",
    "    #Configuración de la conexión con AWS\n",
    "    \n",
    "    s3 = boto3.resource('s3')\n",
    "    bucket = s3.Bucket('xetra-1234')\n",
    "    \n",
    "    #Se asigna el bucket de destino\n",
    "    bucket_target = s3.Bucket('xetra-ajlj')\n",
    "\n",
    "    #Se asigna la fecha de inicio\n",
    "    arg_date = '2022-12-31'\n",
    "    arg_date_dt = datetime.strptime(arg_date, '%Y-%m-%d').date() - timedelta(days=1)\n",
    "    \n",
    "    # ETL\n",
    "    \n",
    "    df_all = extract(bucket, arg_date_dt)\n",
    "    df_transformed = transform_report(df_all, arg_date)\n",
    "    load(df_transformed, bucket_target)\n",
    "    report = etl_report(bucket_target)\n",
    "    print(report)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5f4c044a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE HAN ENCONTRADO LOS OBJETOS CORRECTAMENTE\n",
      "SE HA LEIDO EL ARCHIVO CSV CORRECTAMENTE\n",
      "SE HAN EXTRAIDO LOS DATOS CORRECTAMENTE\n",
      "SE HA TRANSFORMADO EL DATAFRAME\n",
      "SE HA CARGADO EL ARCHIVO PARQUET CORRECTAMENTE\n",
      "xetra_daily_report_20230225_194612.parquet\n",
      "SE HA LEIDO EL ARCHIVO PARQUET DESTINO CORRECTAMENTE\n",
      "      index          ISIN        Date  opening_price_eur  closing_price_eur  \\\n",
      "0         1  AT000000STR1  2022-12-31              36.60              36.70   \n",
      "1         3  AT00000FACC2  2022-12-31               8.05               8.57   \n",
      "2         5  AT0000606306  2022-12-31              14.51              15.00   \n",
      "3         7  AT0000609607  2022-12-31              11.74              12.06   \n",
      "4         9  AT0000644505  2022-12-31              98.20              99.20   \n",
      "...     ...           ...         ...                ...                ...   \n",
      "3227   6455  XS2284324667  2022-12-31              39.48              38.92   \n",
      "3228   6457  XS2314659447  2022-12-31               8.87               8.80   \n",
      "3229   6459  XS2314660700  2022-12-31              22.26              21.92   \n",
      "3230   6461  XS2376095068  2022-12-31              34.29              36.50   \n",
      "3231   6463  XS2434891219  2022-12-31               3.44               3.66   \n",
      "\n",
      "      minimum_price_eur  maximum_price_eur  daily_traded_volume  \\\n",
      "0                 35.75              36.70                 1773   \n",
      "1                  7.87               8.57                10205   \n",
      "2                 13.65              15.28               107836   \n",
      "3                 11.70              12.06                 1065   \n",
      "4                 96.10              99.20                  531   \n",
      "...                 ...                ...                  ...   \n",
      "3227              38.89              39.48                 6124   \n",
      "3228               8.76               8.90                 2000   \n",
      "3229              21.92              22.28                    0   \n",
      "3230              34.06              36.50                 1000   \n",
      "3231               3.42               3.66                    0   \n",
      "\n",
      "      change_prev_closing_%  \n",
      "0                       0.0  \n",
      "1                       0.0  \n",
      "2                       0.0  \n",
      "3                       0.0  \n",
      "4                       0.0  \n",
      "...                     ...  \n",
      "3227                    0.0  \n",
      "3228                    0.0  \n",
      "3229                    0.0  \n",
      "3230                    0.0  \n",
      "3231                    0.0  \n",
      "\n",
      "[3232 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# run\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2fe394",
   "metadata": {},
   "source": [
    "## Reading the uploaded file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9682c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "trg_bucket = 'xetra-bucket-12345'\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_trg = s3.Bucket(trg_bucket)\n",
    "for obj in bucket_trg.objects.all():\n",
    "    print(obj.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac0c5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "prq_obj = bucket_trg.Object(key='xetra_daily_report_20220310_110626.parquet').get().get('Body').read()\n",
    "data = BytesIO(prq_obj)\n",
    "df_report = pd.read_parquet(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c007b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7670c187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
